{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = 'Deep Learning is a subset of machine learning and artificial intelligence that is based on the idea of creating artificial neural networks that can learn from and make predictions about data. It is a very powerful technique that can be used for a wide range of applications, such as image and speech recognition, natural language processing, and predictive analytics.Deep learning algorithms are modeled after the way the human brain processes information and can be trained on large amounts of data, making them highly accurate and efficient. One of the key advantages of deep learning is its ability to learn from unstructured data, such as images and text. This makes it a valuable tool for tasks like image and speech recognition, where traditional machine learning techniques may struggle.Another advantage of deep learning is its ability to improve with more data. As more data is fed into the network, the accuracy of the predictions increases. This is particularly useful for applications such as natural language processing, where the amount of data available is constantly growing.Deep learning is also highly flexible, and can be applied to a wide range of industries, including healthcare, finance, and retail. In healthcare, deep learning algorithms can be used for image analysis to detect diseases such as cancer. In finance, it can be used for fraud detection and credit risk analysis. And in retail, it can be used for personalization and product recommendations.Despite the many advantages of deep learning, it is important to note that it is not a silver bullet. It requires large amounts of data and computational power, and can be difficult to interpret and debug. Additionally, deep learning models are sensitive to the quality of the data, and may not work well with biased or incomplete data.'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenize(words)\n",
    "word_list = word_tokenize(words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILTERING STOP WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is',\n",
       " 'a',\n",
       " 'of',\n",
       " 'and',\n",
       " 'that',\n",
       " 'is',\n",
       " 'on',\n",
       " 'the',\n",
       " 'of',\n",
       " 'that',\n",
       " 'can',\n",
       " 'from',\n",
       " 'and',\n",
       " 'about',\n",
       " 'It',\n",
       " 'is',\n",
       " 'a',\n",
       " 'very',\n",
       " 'that',\n",
       " 'can',\n",
       " 'be',\n",
       " 'for',\n",
       " 'a',\n",
       " 'of',\n",
       " 'such',\n",
       " 'as',\n",
       " 'and',\n",
       " 'and',\n",
       " 'are',\n",
       " 'after',\n",
       " 'the',\n",
       " 'the',\n",
       " 'and',\n",
       " 'can',\n",
       " 'be',\n",
       " 'on',\n",
       " 'of',\n",
       " 'them',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'of',\n",
       " 'is',\n",
       " 'its',\n",
       " 'to',\n",
       " 'from',\n",
       " 'such',\n",
       " 'as',\n",
       " 'and',\n",
       " 'This',\n",
       " 'it',\n",
       " 'a',\n",
       " 'for',\n",
       " 'and',\n",
       " 'where',\n",
       " 'of',\n",
       " 'is',\n",
       " 'its',\n",
       " 'to',\n",
       " 'with',\n",
       " 'more',\n",
       " 'As',\n",
       " 'more',\n",
       " 'is',\n",
       " 'into',\n",
       " 'the',\n",
       " 'the',\n",
       " 'of',\n",
       " 'the',\n",
       " 'This',\n",
       " 'is',\n",
       " 'for',\n",
       " 'such',\n",
       " 'as',\n",
       " 'where',\n",
       " 'the',\n",
       " 'of',\n",
       " 'is',\n",
       " 'is',\n",
       " 'and',\n",
       " 'can',\n",
       " 'be',\n",
       " 'to',\n",
       " 'a',\n",
       " 'of',\n",
       " 'and',\n",
       " 'In',\n",
       " 'can',\n",
       " 'be',\n",
       " 'for',\n",
       " 'to',\n",
       " 'such',\n",
       " 'as',\n",
       " 'In',\n",
       " 'it',\n",
       " 'can',\n",
       " 'be',\n",
       " 'for',\n",
       " 'and',\n",
       " 'And',\n",
       " 'in',\n",
       " 'it',\n",
       " 'can',\n",
       " 'be',\n",
       " 'for',\n",
       " 'and',\n",
       " 'the',\n",
       " 'of',\n",
       " 'it',\n",
       " 'is',\n",
       " 'to',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'It',\n",
       " 'of',\n",
       " 'and',\n",
       " 'and',\n",
       " 'can',\n",
       " 'be',\n",
       " 'to',\n",
       " 'and',\n",
       " 'are',\n",
       " 'to',\n",
       " 'the',\n",
       " 'of',\n",
       " 'the',\n",
       " 'and',\n",
       " 'not',\n",
       " 'with',\n",
       " 'or']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_list = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for word in word_list:\n",
    "    if word.casefold()  in stop_words:\n",
    "        filtered_list.append(word)\n",
    "filtered_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEMMING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep',\n",
       " 'learn',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subset',\n",
       " 'of',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'and',\n",
       " 'artifici',\n",
       " 'intellig',\n",
       " 'that',\n",
       " 'is',\n",
       " 'base',\n",
       " 'on',\n",
       " 'the',\n",
       " 'idea',\n",
       " 'of',\n",
       " 'creat',\n",
       " 'artifici',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'that',\n",
       " 'can',\n",
       " 'learn',\n",
       " 'from',\n",
       " 'and',\n",
       " 'make',\n",
       " 'predict',\n",
       " 'about',\n",
       " 'data',\n",
       " '.',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'veri',\n",
       " 'power',\n",
       " 'techniqu',\n",
       " 'that',\n",
       " 'can',\n",
       " 'be',\n",
       " 'use',\n",
       " 'for',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'rang',\n",
       " 'of',\n",
       " 'applic',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'imag',\n",
       " 'and',\n",
       " 'speech',\n",
       " 'recognit',\n",
       " ',',\n",
       " 'natur',\n",
       " 'languag',\n",
       " 'process',\n",
       " ',',\n",
       " 'and',\n",
       " 'predict',\n",
       " 'analytics.deep',\n",
       " 'learn',\n",
       " 'algorithm',\n",
       " 'are',\n",
       " 'model',\n",
       " 'after',\n",
       " 'the',\n",
       " 'way',\n",
       " 'the',\n",
       " 'human',\n",
       " 'brain',\n",
       " 'process',\n",
       " 'inform',\n",
       " 'and',\n",
       " 'can',\n",
       " 'be',\n",
       " 'train',\n",
       " 'on',\n",
       " 'larg',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'data',\n",
       " ',',\n",
       " 'make',\n",
       " 'them',\n",
       " 'highli',\n",
       " 'accur',\n",
       " 'and',\n",
       " 'effici',\n",
       " '.',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'key',\n",
       " 'advantag',\n",
       " 'of',\n",
       " 'deep',\n",
       " 'learn',\n",
       " 'is',\n",
       " 'it',\n",
       " 'abil',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'from',\n",
       " 'unstructur',\n",
       " 'data',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'imag',\n",
       " 'and',\n",
       " 'text',\n",
       " '.',\n",
       " 'thi',\n",
       " 'make',\n",
       " 'it',\n",
       " 'a',\n",
       " 'valuabl',\n",
       " 'tool',\n",
       " 'for',\n",
       " 'task',\n",
       " 'like',\n",
       " 'imag',\n",
       " 'and',\n",
       " 'speech',\n",
       " 'recognit',\n",
       " ',',\n",
       " 'where',\n",
       " 'tradit',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'techniqu',\n",
       " 'may',\n",
       " 'struggle.anoth',\n",
       " 'advantag',\n",
       " 'of',\n",
       " 'deep',\n",
       " 'learn',\n",
       " 'is',\n",
       " 'it',\n",
       " 'abil',\n",
       " 'to',\n",
       " 'improv',\n",
       " 'with',\n",
       " 'more',\n",
       " 'data',\n",
       " '.',\n",
       " 'as',\n",
       " 'more',\n",
       " 'data',\n",
       " 'is',\n",
       " 'fed',\n",
       " 'into',\n",
       " 'the',\n",
       " 'network',\n",
       " ',',\n",
       " 'the',\n",
       " 'accuraci',\n",
       " 'of',\n",
       " 'the',\n",
       " 'predict',\n",
       " 'increas',\n",
       " '.',\n",
       " 'thi',\n",
       " 'is',\n",
       " 'particularli',\n",
       " 'use',\n",
       " 'for',\n",
       " 'applic',\n",
       " 'such',\n",
       " 'as',\n",
       " 'natur',\n",
       " 'languag',\n",
       " 'process',\n",
       " ',',\n",
       " 'where',\n",
       " 'the',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'data',\n",
       " 'avail',\n",
       " 'is',\n",
       " 'constantli',\n",
       " 'growing.deep',\n",
       " 'learn',\n",
       " 'is',\n",
       " 'also',\n",
       " 'highli',\n",
       " 'flexibl',\n",
       " ',',\n",
       " 'and',\n",
       " 'can',\n",
       " 'be',\n",
       " 'appli',\n",
       " 'to',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'rang',\n",
       " 'of',\n",
       " 'industri',\n",
       " ',',\n",
       " 'includ',\n",
       " 'healthcar',\n",
       " ',',\n",
       " 'financ',\n",
       " ',',\n",
       " 'and',\n",
       " 'retail',\n",
       " '.',\n",
       " 'in',\n",
       " 'healthcar',\n",
       " ',',\n",
       " 'deep',\n",
       " 'learn',\n",
       " 'algorithm',\n",
       " 'can',\n",
       " 'be',\n",
       " 'use',\n",
       " 'for',\n",
       " 'imag',\n",
       " 'analysi',\n",
       " 'to',\n",
       " 'detect',\n",
       " 'diseas',\n",
       " 'such',\n",
       " 'as',\n",
       " 'cancer',\n",
       " '.',\n",
       " 'in',\n",
       " 'financ',\n",
       " ',',\n",
       " 'it',\n",
       " 'can',\n",
       " 'be',\n",
       " 'use',\n",
       " 'for',\n",
       " 'fraud',\n",
       " 'detect',\n",
       " 'and',\n",
       " 'credit',\n",
       " 'risk',\n",
       " 'analysi',\n",
       " '.',\n",
       " 'and',\n",
       " 'in',\n",
       " 'retail',\n",
       " ',',\n",
       " 'it',\n",
       " 'can',\n",
       " 'be',\n",
       " 'use',\n",
       " 'for',\n",
       " 'person',\n",
       " 'and',\n",
       " 'product',\n",
       " 'recommendations.despit',\n",
       " 'the',\n",
       " 'mani',\n",
       " 'advantag',\n",
       " 'of',\n",
       " 'deep',\n",
       " 'learn',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'import',\n",
       " 'to',\n",
       " 'note',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'silver',\n",
       " 'bullet',\n",
       " '.',\n",
       " 'it',\n",
       " 'requir',\n",
       " 'larg',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'data',\n",
       " 'and',\n",
       " 'comput',\n",
       " 'power',\n",
       " ',',\n",
       " 'and',\n",
       " 'can',\n",
       " 'be',\n",
       " 'difficult',\n",
       " 'to',\n",
       " 'interpret',\n",
       " 'and',\n",
       " 'debug',\n",
       " '.',\n",
       " 'addit',\n",
       " ',',\n",
       " 'deep',\n",
       " 'learn',\n",
       " 'model',\n",
       " 'are',\n",
       " 'sensit',\n",
       " 'to',\n",
       " 'the',\n",
       " 'qualiti',\n",
       " 'of',\n",
       " 'the',\n",
       " 'data',\n",
       " ',',\n",
       " 'and',\n",
       " 'may',\n",
       " 'not',\n",
       " 'work',\n",
       " 'well',\n",
       " 'with',\n",
       " 'bias',\n",
       " 'or',\n",
       " 'incomplet',\n",
       " 'data',\n",
       " '.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in word_list]\n",
    "stemmed_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAGGING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tag = nltk.pos_tag(word_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEMMINATIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bad'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in word_list]\n",
    "lemmatized_words\n",
    "# for adjective\n",
    "lemmatizer.lemmatize(\"worst\", pos=\"a\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "chunk_parser = nltk.RegexpParser(grammar)\n",
    "tree = chunk_parser.parse(word_tag)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHINKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Deep/JJ\n",
      "  (Chunk\n",
      "    Learning/NNP\n",
      "    is/VBZ\n",
      "    a/DT\n",
      "    subset/NN\n",
      "    of/IN\n",
      "    machine/NN\n",
      "    learning/NN\n",
      "    and/CC)\n",
      "  artificial/JJ\n",
      "  (Chunk\n",
      "    intelligence/NN\n",
      "    that/WDT\n",
      "    is/VBZ\n",
      "    based/VBN\n",
      "    on/IN\n",
      "    the/DT\n",
      "    idea/NN\n",
      "    of/IN\n",
      "    creating/VBG)\n",
      "  artificial/JJ\n",
      "  neural/JJ\n",
      "  (Chunk\n",
      "    networks/NNS\n",
      "    that/WDT\n",
      "    can/MD\n",
      "    learn/VB\n",
      "    from/IN\n",
      "    and/CC\n",
      "    make/VB\n",
      "    predictions/NNS\n",
      "    about/IN\n",
      "    data/NNS\n",
      "    ./.\n",
      "    It/PRP\n",
      "    is/VBZ\n",
      "    a/DT\n",
      "    very/RB)\n",
      "  powerful/JJ\n",
      "  (Chunk technique/NN that/WDT can/MD be/VB used/VBN for/IN a/DT)\n",
      "  wide/JJ\n",
      "  (Chunk range/NN of/IN applications/NNS ,/,)\n",
      "  such/JJ\n",
      "  (Chunk as/IN image/NN and/CC speech/NN recognition/NN ,/,)\n",
      "  natural/JJ\n",
      "  (Chunk language/NN processing/NN ,/, and/CC)\n",
      "  predictive/JJ\n",
      "  (Chunk\n",
      "    analytics.Deep/NN\n",
      "    learning/NN\n",
      "    algorithms/NN\n",
      "    are/VBP\n",
      "    modeled/VBN\n",
      "    after/IN\n",
      "    the/DT\n",
      "    way/NN\n",
      "    the/DT)\n",
      "  human/JJ\n",
      "  (Chunk\n",
      "    brain/NN\n",
      "    processes/VBZ\n",
      "    information/NN\n",
      "    and/CC\n",
      "    can/MD\n",
      "    be/VB\n",
      "    trained/VBN\n",
      "    on/IN)\n",
      "  large/JJ\n",
      "  (Chunk\n",
      "    amounts/NNS\n",
      "    of/IN\n",
      "    data/NNS\n",
      "    ,/,\n",
      "    making/VBG\n",
      "    them/PRP\n",
      "    highly/RB)\n",
      "  accurate/JJ\n",
      "  (Chunk and/CC)\n",
      "  efficient/JJ\n",
      "  (Chunk ./. One/CD of/IN the/DT)\n",
      "  key/JJ\n",
      "  (Chunk advantages/NNS of/IN)\n",
      "  deep/JJ\n",
      "  (Chunk\n",
      "    learning/NN\n",
      "    is/VBZ\n",
      "    its/PRP$\n",
      "    ability/NN\n",
      "    to/TO\n",
      "    learn/VB\n",
      "    from/IN)\n",
      "  unstructured/JJ\n",
      "  (Chunk data/NNS ,/,)\n",
      "  such/JJ\n",
      "  (Chunk\n",
      "    as/IN\n",
      "    images/NNS\n",
      "    and/CC\n",
      "    text/NN\n",
      "    ./.\n",
      "    This/DT\n",
      "    makes/VBZ\n",
      "    it/PRP\n",
      "    a/DT)\n",
      "  valuable/JJ\n",
      "  (Chunk\n",
      "    tool/NN\n",
      "    for/IN\n",
      "    tasks/NNS\n",
      "    like/IN\n",
      "    image/NN\n",
      "    and/CC\n",
      "    speech/NN\n",
      "    recognition/NN\n",
      "    ,/,\n",
      "    where/WRB)\n",
      "  traditional/JJ\n",
      "  (Chunk\n",
      "    machine/NN\n",
      "    learning/VBG\n",
      "    techniques/NNS\n",
      "    may/MD\n",
      "    struggle.Another/VB\n",
      "    advantage/NN\n",
      "    of/IN)\n",
      "  deep/JJ\n",
      "  (Chunk\n",
      "    learning/NN\n",
      "    is/VBZ\n",
      "    its/PRP$\n",
      "    ability/NN\n",
      "    to/TO\n",
      "    improve/VB\n",
      "    with/IN\n",
      "    more/JJR\n",
      "    data/NNS\n",
      "    ./.\n",
      "    As/IN\n",
      "    more/JJR\n",
      "    data/NNS\n",
      "    is/VBZ\n",
      "    fed/VBN\n",
      "    into/IN\n",
      "    the/DT\n",
      "    network/NN\n",
      "    ,/,\n",
      "    the/DT\n",
      "    accuracy/NN\n",
      "    of/IN\n",
      "    the/DT\n",
      "    predictions/NNS\n",
      "    increases/VBZ\n",
      "    ./.\n",
      "    This/DT\n",
      "    is/VBZ\n",
      "    particularly/RB)\n",
      "  useful/JJ\n",
      "  (Chunk for/IN applications/NNS)\n",
      "  such/JJ\n",
      "  (Chunk as/IN)\n",
      "  natural/JJ\n",
      "  (Chunk\n",
      "    language/NN\n",
      "    processing/NN\n",
      "    ,/,\n",
      "    where/WRB\n",
      "    the/DT\n",
      "    amount/NN\n",
      "    of/IN\n",
      "    data/NNS)\n",
      "  available/JJ\n",
      "  (Chunk is/VBZ constantly/RB)\n",
      "  growing.Deep/JJ\n",
      "  (Chunk learning/NN is/VBZ also/RB highly/RB)\n",
      "  flexible/JJ\n",
      "  (Chunk ,/, and/CC can/MD be/VB applied/VBN to/TO a/DT)\n",
      "  wide/JJ\n",
      "  (Chunk\n",
      "    range/NN\n",
      "    of/IN\n",
      "    industries/NNS\n",
      "    ,/,\n",
      "    including/VBG\n",
      "    healthcare/NN\n",
      "    ,/,\n",
      "    finance/NN\n",
      "    ,/,\n",
      "    and/CC)\n",
      "  retail/JJ\n",
      "  (Chunk ./. In/IN healthcare/NN ,/,)\n",
      "  deep/JJ\n",
      "  (Chunk\n",
      "    learning/NN\n",
      "    algorithms/NNS\n",
      "    can/MD\n",
      "    be/VB\n",
      "    used/VBN\n",
      "    for/IN\n",
      "    image/NN\n",
      "    analysis/NN\n",
      "    to/TO\n",
      "    detect/VB\n",
      "    diseases/NNS)\n",
      "  such/JJ\n",
      "  (Chunk\n",
      "    as/IN\n",
      "    cancer/NN\n",
      "    ./.\n",
      "    In/IN\n",
      "    finance/NN\n",
      "    ,/,\n",
      "    it/PRP\n",
      "    can/MD\n",
      "    be/VB\n",
      "    used/VBN\n",
      "    for/IN\n",
      "    fraud/NN\n",
      "    detection/NN\n",
      "    and/CC\n",
      "    credit/NN\n",
      "    risk/NN\n",
      "    analysis/NN\n",
      "    ./.\n",
      "    And/CC\n",
      "    in/IN)\n",
      "  retail/JJ\n",
      "  (Chunk\n",
      "    ,/,\n",
      "    it/PRP\n",
      "    can/MD\n",
      "    be/VB\n",
      "    used/VBN\n",
      "    for/IN\n",
      "    personalization/NN\n",
      "    and/CC\n",
      "    product/NN\n",
      "    recommendations.Despite/VBP\n",
      "    the/DT)\n",
      "  many/JJ\n",
      "  (Chunk advantages/NNS of/IN)\n",
      "  deep/JJ\n",
      "  (Chunk learning/NN ,/, it/PRP is/VBZ)\n",
      "  important/JJ\n",
      "  (Chunk to/TO note/VB that/IN it/PRP is/VBZ not/RB a/DT)\n",
      "  silver/JJ\n",
      "  (Chunk bullet/NN ./. It/PRP requires/VBZ)\n",
      "  large/JJ\n",
      "  (Chunk amounts/NNS of/IN data/NNS and/CC)\n",
      "  computational/JJ\n",
      "  (Chunk power/NN ,/, and/CC can/MD be/VB)\n",
      "  difficult/JJ\n",
      "  (Chunk to/TO interpret/VB and/CC debug/VB ./. Additionally/RB ,/,)\n",
      "  deep/JJ\n",
      "  (Chunk learning/NN models/NNS are/VBP)\n",
      "  sensitive/JJ\n",
      "  (Chunk\n",
      "    to/TO\n",
      "    the/DT\n",
      "    quality/NN\n",
      "    of/IN\n",
      "    the/DT\n",
      "    data/NN\n",
      "    ,/,\n",
      "    and/CC\n",
      "    may/MD\n",
      "    not/RB\n",
      "    work/VB\n",
      "    well/RB\n",
      "    with/IN\n",
      "    biased/VBN\n",
      "    or/CC)\n",
      "  incomplete/JJ\n",
      "  (Chunk data/NNS ./.))\n"
     ]
    }
   ],
   "source": [
    "grammar = \"\"\"\n",
    "... Chunk: {<.*>+}\n",
    "...        }<JJ>{\"\"\"\n",
    "chunk_parser = nltk.RegexpParser(grammar)\n",
    "tree = chunk_parser.parse(word_tag)\n",
    "print(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98f695c938581e5a1ca220556a862bb7bb81b179544d4b01b718a9c0b2a8c66a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
